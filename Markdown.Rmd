---
title: "Predicting House Prices"
author: "Alberto Lombatti"
date: "5/21/2019"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Libraries used
These are the libraries I have used in order to complete the project
```{r, warning = FALSE, message = FALSE}
library(ggplot2)
library(corrplot)
library(Stack)
library(fastDummies)
library(dplyr)
library(leaflet)
```


### Import the data
The data is uploaded on a gist, and we store it in two data.frame objects called _train_ and _test_
```{r}
train <- read.csv("https://gist.githubusercontent.com/alombatti/f2cb8f1a244784999353309a97a6777f/raw/f38ee90641da97f62964ac10ea558564bfc6cb65/house_price_train.csv")
```

```{r}
test <- read.csv("https://gist.githubusercontent.com/alombatti/1df87e336f159842e64ced9380b13e25/raw/49ea0fe6b42fb5d4868e1291dc8e47b20d2cc3bd/house_price_test.csv")
```

## Data understanding
This dataset contains house sale prices for King County, which includes Seattle, Washington. It includes homes sold between May 2014 and May 2015. The dataset provided to us has already been devided in train set and test set, in the sizes of 17277 observations for the train and 4320 observations for the test.

The fields describing the data are:

1. __id__: a notation for a house
2. __date__: the date the house was sold
3. __price__: the prediction target, consisting in the amount in US Dollars the house was sold at
4. __bedrooms__: the number of bedrooms in the house
5. __bathrooms__: the number of bathrooms in the house
6. __sqft_living__: square footage of the home
7. __sqft_lot__: square footage of the lot
8. __floors__: total floors (levels) in the house
9. __waterfront__: use which has a view to the waterfront
10. __view__: how many times the house has been viewed
11. __condition__: overall condition of the house
12. __grade__: overall grade given to the housing unit, based on King County grading system
13. __sqft_above__: square footage of house apart from basement
14. __sqft_basement__: square footage of the basement
15. ___yr_built__: the year in which the house was completed
16. __yr_renovated__: year when house was renovated
17. __zipcode__: zip
18. __lat__: latitude coordinate
19. __long__: longitude coordinate
20. __sqft_living15__: living room area in 2015 (if different fron sqft_living, it implies some renovations)
21. __sqft_lot15__: lot area in 2015 (if different from sqft_lot, it implies some renovations)

*** 

Here is a glimpse of what the __STRUCTURE__ of the data looks like (for the train set)
```{r}
str(train)
```

*** 

We then check for NAs in the data we are going to use, both in the train and in the test.
```{r}
print(length(which(is.na(train) == T)))
print(length(which(is.na(test) == T)))
```
As we can see, the data does not contain any null values, so we can proceed with our analysis.

### Transformation of the DATE field

In order to analyze the field _DATE_, and to be able to determine whether it is relevant in our analysis, we have to transform it so that we can use it.
I thought of separating the fields year, month, and day, to, further in the analysis, determine if any of them is directly correlated with the price.

First, I change the field _date_ from factor to date, and I store in a new dataframe the complete field of the date, its year, its month, and its day.
Then, I merge the newly created dataset with the one from which I extracted the date field, and I reorder the column in a way that makes sense for the analyais.

I repeat the same procedure for the _test_ and the _train_ datasets.
```{r}
train$date <- as.Date(train$date, "%m/%d/%Y")
df.date_train <- data.frame(date = train$date,
                      year = as.numeric(format(train$date, format = "%Y")),
                      month = as.numeric(format(train$date, format = "%m")),
                      day = as.numeric(format(train$date, format = "%d")))

train <- unique(merge(train, df.date_train))
rm(df.date_train)
train <- train[, c(2, 1, 22, 23, 24, 3:21)]
```

```{r}
test$date <- as.Date(test$date, "%m/%d/%Y")
df.date_test <- data.frame(date = test$date,
                           year = as.numeric(format(test$date, format = "%Y")),
                           month = as.numeric(format(test$date, format = "%m")),
                           day = as.numeric(format(test$date, format = "%d")))

test <- unique(merge(test, df.date_test))
rm(df.date_test)
test <- test[, c(2, 1, 21, 22, 23, 3:20)]
```

***

Now I stack together the train and test dataset to procede with a more accurate analysis. I also eliminate the field __id__ and __date__ because they are not going to be relevant.
```{r}
complete <- Stack(train, test)
complete$id = NULL
complete$date = NULL
```

The dataset now looks like this:
```{r}
head(complete)
```

## Correlation matrix
Now I plot a correlation graph to see how much the different variables are correlated to our target variable _PRICE_
```{r}
corr = cor(train[, 3:24])

corrplot(corr, method = "color",
         outline = T,
         cl.pos = "n",
         rect.col = "black",
         tl.col = "indianred4",
         addCoef.col = "black",
         number.digits = 2,
         number.cex = 0.60,
         tl.cex = 0.7,
         cl.cex = 1,
         col = colorRampPalette(c("red", "white", "green4")) (100))
```

From the matrix, we can see that we have many variables correlated somehow with price, some more and some less. I decided to proceed my analysis keeoing only the variables that have a correlation >= 0.15 with the target variable.

Therefore, going forward I will only keep:

1. price
2. bedrooms
3. bathrooms
4. sqft_living
5. floors
6. waterfront
7. view
8. grade
9. sqft_above
10. sqft_basement
11. lat
12. sqft_living15

Nonetheless, some considerations have to be made. The variables __condition__, __yr_renovated__, and __zipcode__ are going to be converted as factors further on in the analysis. Therefore, we still include them in the listof variables we are going to keep because we can not really interepret their value now since it is numeric, and as numeric it might not affect the correlation with _price_.
```{r}
complete2 <- select(complete, "price", "bedrooms", "bathrooms", "sqft_living", "floors",
                    "waterfront", "view", "grade", "sqft_above", "sqft_basement", "lat",
                    "sqft_living15", "condition", "yr_renovated", "zipcode")
```

## Data Visualization

This is an interactive map with all the houses based on their geographical position, coloured by their price.
```{r}
complete$PriceBin<-cut(complete$price, c(0,250e3,500e3,750e3,1e6,2e6,999e6))

center_lon = median(complete$long,na.rm = TRUE)
center_lat = median(complete$lat,na.rm = TRUE)

factpal <- colorFactor(c("black","blue","yellow","orange","#0B5345","red"), 
                      complete$PriceBin)



leaflet(complete) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat, 
             color = ~factpal(PriceBin))  %>%
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%
  
  addLegend("bottomright", pal = factpal, values = ~PriceBin,
            title = "House Price Distribution",
            opacity = 1)
```

In this section we are going to analyze the relationship of all the varaibles with our target, the variable _price_. Before doing this, I create a copy of the dataset, and I split it in *train* and *test*, based on the value of the variable price.
```{r}
complete2 <- complete

train2 <- split(complete2, complete2$price > 0)
train2 <- train2[["TRUE"]]

test2 <- split(complete2, is.na(complete2$price))
test2 <- test2[["TRUE"]]
```

### Distribution of prices
Here we look at the histrogram showing how many houses have been sold for each price.
```{r, message = FALSE}
graph1 <- ggplot(data = train2, aes(x = price)) +    
  geom_histogram(alpha = 0.8, fill = "#F1C40F") +
  labs(x = "price", y = "houses", title = "Distribution of Prices") +
  theme_bw()

graph1
```

Since the interval of price of the houses is very wide, it is smart to focus only on a small segment, to see the patten where most of the houses are. In this histogram, we only see the distribution of houses sold at a price up to 1.5 million US Dollars.
```{r, message = FALSE, warning = FALSE}
graph2 <- ggplot(data = train2, aes(x = price)) +    
  geom_histogram(alpha = 0.8, fill = "#F1C40F") +
  scale_x_continuous(limits=c(0, 1.5e6)) +
  labs(x = "price", y = "houses", title = "Distribution of Prices (up to 1.5 million)") +
  theme_bw()

graph2
```

***

For the sole purpose of data visualization, I now add a comuln to my _train_ dataframe rapresenting the __logarithmic transformation__ of the price, so that the graphs will look prettier and more understandable.
```{r, message = FALSE, warning = FALSE}
train2$logprice = log(train2$price)
```

### Boxplot between price and bedrooms
```{r}
graph3 <- boxplot(train2[, "logprice"] ~ train2[, "bedrooms"],
                  main = "Price vs Bedrooms", col=c("#F1C40F","#336633"),
                  xlab="bedrooms", ylab="log (price)")
```

From this graph, we notice there are two odd values, when the bedrooms are 11 and when the bedrooms are 33.

```{r}
print(subset(train2, train2$bedrooms > 10))
```

In fact, we can see all the houses with a number of bedrooms bigger than 10 is just two, therefore we exclude these records from our analysis not to disturb our model.

### Boxplot between price and bathrooms
```{r}
graph4 <- boxplot(train2[, "logprice"] ~ train2[, "bathrooms"],
                  main = "Price vs Bathrooms", col=c("#F1C40F","#336633"),
                  xlab="bathrooms", ylab="log (price)")
```

The relationship looks linear overall. Nonetheless, the price of the house with 7.5 bathrooms is relatively lower than its neighbours. Therefore, we decide to eliminate that value.

### Boxplot between price and floors
```{r}
graph5 <- boxplot(train2[, "logprice"] ~ train2[, "floors"],
                  main = "Price vs Floors", col=c("#F1C40F","#336633"),
                  xlab="floors", ylab="log (price)")
```

The relationship is linear.

### Boxplot between price and waterfront
```{r}
graph6 <- boxplot(train2[, "logprice"] ~ train2[, "waterfront"],
                  main = "Price vs Waterfront", col=c("#F1C40F","#336633"),
                  xlab="waterfront", ylab="log (price)")
```

The relationsip is linear. Here, the 0 rapresents the houses without a waterfront, while the value 1 rapresents the houses with a waterfront. It is common sense that, if the house has a waterfront, its price is higher.

### Boxplot between price and view
```{r}
graph7 <- boxplot(train2[, "logprice"] ~ train2[, "view"],
                  main = "Price vs View", col=c("#F1C40F","#336633"),
                  xlab="view", ylab="log (price)")
```

The relationsip is linear. Here, the 0 rapresents the worst view, while the value 4 rapresents the best view. It is common sense that, the more beautiful the view, the higher the price of the house.

### Boxplot between price and condition
```{r}
graph8 <- boxplot(train2[, "logprice"] ~ train2[, "condition"],
                  main = "Price vs Condition", col=c("#F1C40F","#336633"),
                  xlab="condition", ylab="log (price)")
```

The relationship is linear.

### Boxplot between price and grade
```{r}
graph9 <- boxplot(train2[, "logprice"] ~ train2[, "grade"],
                  main = "Price vs Grade", col=c("#F1C40F","#336633"),
                  xlab="grade", ylab="log (price)")
```

The relationship is linear.

### Boxplot between price and sqft_living
```{r}
graph10 <- boxplot(train2[, "logprice"] ~ train2[, "sqft_living"],
                  main = "Price vs sqft_Living", col=c("#F1C40F","#336633"),
                  xlab="sqft_living", ylab="log (price)")
```

The relationship looks linear. The bigger the living room, the higher the price of the house.

### Boxplot between price and sqft_basement
```{r}
graph11 <- boxplot(train2[, "logprice"] ~ train2[, "sqft_basement"],
                   main = "Price vs sqft_Basement", col=c("#F1C40F","#336633"),
                   xlab="sqft_basement", ylab="log (price)")
```

This graph is interesting. Here, we can see that a lot of houses do not have a basement at all, while tbe houses that have a basement, even if the size of the basement changes a lot, their prices do not really change.
```{r}
length(train2$sqft_basement[train2$sqft_basement == 0])
```

```{r}
length(train2$sqft_basement[train2$sqft_basement != 0])
```

Therefore, I decided to simplify this field and make it a boolean: it will take value 0 if the house does not have a basement, and it will take value 1 if the house has a basement, no matter its size.

### Boxplot between price and yr_renovated
```{r}
graph12 <- boxplot(train2[, "logprice"] ~ train2[, "yr_renovated"],
                   main = "Price vs yr_Renovated", col=c("#F1C40F","#336633"),
                   xlab="yr_renovated", ylab="log (price)")
```

This graph is very similar to the previous one regarding the basement situation. As for having a basement or not, the same reasoning can be applied to the renovation of the house. It does not really matter when the house has been renovated, but what matters is if the house has been renovated at all.
```{r}
length(train2$yr_renovated[train2$yr_renovated == 0])
```

```{r}
length(train2$yr_renovated[train2$yr_renovated != 0])
```

As we can see, most of the houses have not been renovated, so we will transform this field into boolean.

### Boxplot between price and zipcode
```{r}
graph13 <- boxplot(train2[, "logprice"] ~ train2[, "zipcode"],
                   main = "Price vs Zipcode", col=c("#F1C40F","#336633"),
                   xlab="zipcode", ylab="log (price)")
```

We can not really see a pattern in this graph, so we will categorize the variable when modelling (as predicted before).

### Boxplot between price and sqft_living15
```{r}
graph14 <- boxplot(train2[, "logprice"] ~ train2[, "sqft_living15"],
                   main = "Price vs sqft_Living(15)", col=c("#F1C40F","#336633"),
                   xlab="sqft_living(15)", ylab="log (price)")
```

As for the variable *sqft_living*, we see a direct relationship in this graph. As the area of the living room increases, the price ofthe house increases as well.

***
***
***

Given all the insights from the data visualization section, we can proceed in apply the changes to our dataset.

First, as seen in the graph for the bathrooms, we eliminate the bathroom with value 7.5 because its price was odd and probably it was a mistake.
```{r}
train2 <- train2[-5419, ]
```

Then, as seen in the graph for the bedrooms, we only keep those house with 10 or less bedrooms, since the two houses with 11 and 33 bedrooms had wrong values for their price.
```{r}
train2 <- train2[train2$bedrooms <= 10, ]
```

We dummify the *sqft_basement* field, transforming all the houses with a basement with value 1, and keeping all the houses without a basement with value 0.
```{r}
train2$sqft_basement[train2$sqft_basement != 0] = 1
test2$sqft_basement[test2$sqft_basement != 0] = 1
```

We dummify the *yr_renovated* field, transforming all the houses that has been renovated with value 1, and keeping all the houses without renovation with value 0.
```{r}
train2$yr_renovated[train2$yr_renovated != 0] = 1
test2$yr_renovated[test2$yr_renovated != 0] = 1
```

***
***
***

Lastly, we stack back together the train and test set.
```{r}
train2$logprice <- NULL
complete2 <- Stack(train2, test2)
```

## Data Transformation

I create a copy of the complete dataset to proceed with the analysis.
```{r}
complete3 <- complete2
```

Now, it is time to __standardize__ the variables involving the squarefeet. I create a function that normalizes the value of the field between 0 and 1, 0 being the lowest value and 1 being the highest.
```{r}
range01 <- function(x) {
  (x-min(x)) / (max(x)-min(x))
}
```

Therefore, I can proceed with the normalization of the variables **sqft_living**, **sqft_above**, and **sqft_living15**.
```{r}
complete3$sqft_living <- range01(complete3$sqft_living)
```

```{r}
complete3$sqft_above <- scale(complete3$sqft_above)
```

```{r}
complete3$sqft_living15 <- scale(complete3$sqft_living15)
```

***

In order to proceed with the design of the model, I transform __as factor__ the following variables because they do not make sense as numeric in this context:

1. bathrooms
2. floors
3. waterfront
4. view
5. grade
6. sqft_basement
7. yr_renovated
8. condition
9. zipcode
```{r}
complete3$bedrooms <- as.factor(complete2$bedrooms)
complete3$bathrooms <- as.factor(complete2$bathrooms)
complete3$floors <- as.factor(complete2$floors)
complete3$waterfront <- as.factor(complete2$waterfront)
complete3$view <- as.factor(complete2$view)
complete3$grade <- as.factor(complete2$grade)
complete3$sqft_basement <- as.factor(complete3$sqft_basement)
complete3$yr_renovated <- as.factor(complete3$yr_renovated)
complete3$condition <- as.factor(complete3$condition)
complete3$zipcode <- as.factor(complete3$zipcode)
```

Another variable that does not make sense to take as numeric is **lat**. Nonetheless, we can not consider it as factor neither because of the too many values it takes.

Therefore, we _bin_ the factor in 13 intervals.
```{r}
breaks_lat <- c(-Inf, 47.20, 47.25, 47.30, 47.35, 47.40, 47.45, 47.50, 47.55, 47.60,
                47.65, 47.70, 47.75, Inf)

names_lat <- c("47.15 - 47.20", "47.20 - 47.25", "47.25 - 47.30", "47.30 - 47.35",
               "47.35 - 47.40", "47.40 - 47.45", "47.45 - 47.50", "47.50 - 47.55",
               "47.55 - 47.60", "47.60 - 47.65", "47.65 - 47.70", "47.70 - 47.75",
               "47.75 - 47.80")

complete3$lat <- cut(complete3$lat, breaks = breaks_lat, labels = names_lat)
```

***

In the end, I unstack the train and test dataset from the complete dataset to build our model.
```{r}
train3 <- split(complete3, complete3$price > 0)
train3 <- train3[["TRUE"]]

test3 <- split(complete3, is.na(complete3$price))
test3 <- test3[["TRUE"]]
```

## Model
I decided to use a **linear regression** model on the train dataset with all the variables available.
```{r}
model1 <- lm(formula = price ~ bedrooms +
               bathrooms +
               sqft_living +
               floors +
               waterfront +
               view +
               grade +
               sqft_above +
               sqft_basement +
               sqft_living15 +
               lat +
               condition +
               yr_renovated +
               zipcode,
               data = train3)
```

The model scores an R2 of 0.84, which is a relatively good result.
```{r}
summary(model1)
```

I notice that the variable **sqft_basement** is not significant, so I re-model without that variable.
```{r}
model2 <- lm(formula = price ~ bedrooms +
               bathrooms +
               sqft_living +
               floors +
               waterfront +
               view +
               grade +
               sqft_above +
               sqft_living15 +
               lat +
               condition +
               yr_renovated +
               zipcode,
               data = train3)
```

```{r}
summary(model2)
```

Unfortunately, after taking out *sqtf_basement*, the model did not improve.

Then, we fit the model to our dataset to predict the price of every house in the train dataset, to see if they reflect the actual value.
```{r}
train3_fit <- fitted(model2)
train3$pred <- train3_fit
```

We have to score our model on the **MAPE**, which is the mean absolute percentage error. The lowest this number, the better the model.
```{r}
mape <- function(real, predicted) {
  return(mean(abs((real - predicted) / real)))
}
```

```{r}
mape(train3$price, train3$pred)
```
We get a MAPE score of `r mape(train3$price, train3$pred)`, which is very good for our model.

Last, with our model we predictthe prices in the test dataset.
```{r}
test3$price <- predict(model2, test3)
```